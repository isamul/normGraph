{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper notebook for benchmarking the GPT-4o reference model\n",
    "\n",
    "This notebook imports a csv-file containing a set of questions and saves the input- and output-tokens of the model responses to a dedicated csv-file. This notebook specifically tests the vanilla `GPT-4o-mini` PLM by *OpenAI*. The actual answers were extracted from the notebook variable `res_only`, accessible after running the corresponding cells below. For further information on the actual results, refer to the file ``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prompt\n",
    "\n",
    "message = \"\"\"Sie sind ein experte in Sachen Normen und Standards im Bauwesen. Beantworten Sie mir die folgende Frage und geben sie mir immer die Quelle an (Kapitel und Abschnitte), aus der die Antwort stammt.\\\n",
    "Die Fragen beziehen sich auf die Normenreihe DIN EN 1991-1-3:2010-12 oder DIN EN 1991-1-3/NA:2019-04 \\\n",
    "Hier nun die Frage: {Frage} \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "response = model.invoke(message.format(Frage=\"In welchem Jahr wurde die Norm EN 1990 verÃ¶ffentlicht?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def get_chatgpt_response(question: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Get a response from the ChatGPT model for a given question.\n",
    "    \n",
    "    Args:\n",
    "    question (str): The question to ask the model.\n",
    "    \n",
    "    Returns:\n",
    "    Dict: A dictionary containing the response content and token usage.\n",
    "    \"\"\"\n",
    "    response = model.invoke(message.format(Frage=question)\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"content\": response.content,\n",
    "        \"prompt_tokens\": response.response_metadata['token_usage']['prompt_tokens'],\n",
    "        \"completion_tokens\": response.response_metadata['token_usage']['completion_tokens']\n",
    "    }\n",
    "\n",
    "def process_questions(questions: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process a list of questions using the ChatGPT model.\n",
    "    \n",
    "    Args:\n",
    "    questions (List[str]): A list of questions to ask the model.\n",
    "    \n",
    "    Returns:\n",
    "    List[Dict]: A list of dictionaries containing the responses and their metadata.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for question in questions:\n",
    "        response = get_chatgpt_response(question)\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"response\": response[\"content\"],\n",
    "            \"prompt_tokens\": response[\"prompt_tokens\"],\n",
    "            \"completion_tokens\": response[\"completion_tokens\"]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_to_csv(data: List[Dict], filename: str):\n",
    "    \"\"\"\n",
    "    Save the data to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "    data (List[Dict]): The data to save.\n",
    "    filename (str): The name of the file to save to.\n",
    "    \"\"\"\n",
    "    keys = data[0].keys()\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('questions.csv', delimiter=';')\n",
    "\n",
    "question_list = df['Questions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = process_questions(question_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_only = [response[\"response\"] for response in responses]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"token_counts.csv\"\n",
    "\n",
    "# Extract prompt_tokens and completion_tokens and write to CSV\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['prompt_tokens', 'completion_tokens']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for item in responses:\n",
    "        writer.writerow({\n",
    "            'prompt_tokens': item['prompt_tokens'],\n",
    "            'completion_tokens': item['completion_tokens']\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
